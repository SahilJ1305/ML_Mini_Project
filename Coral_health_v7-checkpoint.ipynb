{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "748cff15-3a25-46cc-aaa2-f57244bb00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch   #v7.1\n",
    "# import random\n",
    "# import math\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from pathlib import Path\n",
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "# from ultralytics import YOLO\n",
    "# from torchvision import transforms\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "\n",
    "import torch   #V7.2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14b6bee-2797-4e29-9b00-a7afa61408dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CoralReefClassifier:\n",
    "#     def __init__(self, yaml_path, pretrained_weights='yolov8n.pt'):\n",
    "#         \"\"\"\n",
    "#         Initialize YOLO model with coral-specific augmentations\n",
    "        \n",
    "#         Args:\n",
    "#             yaml_path (str): Path to dataset YAML config\n",
    "#             pretrained_weights (str): Initial weights path\n",
    "#         \"\"\"\n",
    "#         self.device = self._setup_device()\n",
    "#         self.model = YOLO(pretrained_weights).to(self.device)\n",
    "#         self.yaml_path = yaml_path\n",
    "#         self.class_names = ['Bleached', 'Dead', 'Healthy']\n",
    "        \n",
    "#         # Coral-specific augmentations\n",
    "#         self.color_transforms = transforms.Compose([\n",
    "#             transforms.ColorJitter(\n",
    "#                 brightness=(0.8, 1.2),\n",
    "#                 contrast=(0.7, 1.3),\n",
    "#                 saturation=(0.6, 1.4),\n",
    "#                 hue=(-0.1, 0.1)\n",
    "#             ),\n",
    "#             transforms.RandomAdjustSharpness(1.5, p=0.3),\n",
    "#             transforms.RandomGrayscale(p=0.1)\n",
    "#         ])\n",
    "\n",
    "#     def _setup_device(self):\n",
    "#         \"\"\"Configure device with CUDA error handling\"\"\"\n",
    "#         try:\n",
    "#             if torch.cuda.is_available():\n",
    "#                 torch.backends.cudnn.benchmark = True\n",
    "#                 return 'cuda'\n",
    "#             return 'cpu'\n",
    "#         except RuntimeError as e:\n",
    "#             print(f\"CUDA error: {e}\\nFalling back to CPU\")\n",
    "#             return 'cpu'\n",
    "\n",
    "#     def _apply_coral_augmentations(self, img):\n",
    "#         \"\"\"Apply underwater-specific augmentations\"\"\"\n",
    "#         img = self.color_transforms(img)\n",
    "        \n",
    "#         # Water surface effects\n",
    "#         if random.random() < 0.3:\n",
    "#             img = self._add_water_surface_effect(img)\n",
    "            \n",
    "#         # Particulate matter\n",
    "#         if random.random() < 0.2:\n",
    "#             img = self._add_particulate_effect(img)\n",
    "            \n",
    "#         return img\n",
    "\n",
    "#     def _add_water_surface_effect(self, img):\n",
    "#         \"\"\"Add light refraction patterns\"\"\"\n",
    "#         img = np.array(img)\n",
    "#         rows, cols = img.shape[:2]\n",
    "        \n",
    "#         for i in range(rows):\n",
    "#             offset = int(5 * math.sin(2*math.pi*i/120))\n",
    "#             img[i,:] = np.roll(img[i,:], offset, axis=0)\n",
    "            \n",
    "#         return Image.fromarray(img)\n",
    "\n",
    "#     def _add_particulate_effect(self, img):\n",
    "#         \"\"\"Add floating particulate matter\"\"\"\n",
    "#         img = np.array(img)\n",
    "#         h, w = img.shape[:2]\n",
    "        \n",
    "#         for _ in range(random.randint(10, 30)):\n",
    "#             x, y = random.randint(0, w-1), random.randint(0, h-1)\n",
    "#             size = random.randint(1, 3)\n",
    "#             color = random.choice([(200,200,200), (150,150,150)])\n",
    "#             cv2.circle(img, (x,y), size, color, -1)\n",
    "            \n",
    "#         return Image.fromarray(img)\n",
    "\n",
    "#     def train(self, epochs=220, batch_size=8, patience=50):\n",
    "#         \"\"\"\n",
    "#         Train model with coral-specific parameters\n",
    "        \n",
    "#         Returns:\n",
    "#             Trained YOLO model\n",
    "#         \"\"\"\n",
    "#         results = self.model.train(\n",
    "#             data=self.yaml_path,\n",
    "#             epochs=epochs,\n",
    "#             batch=batch_size,\n",
    "#             imgsz=512,\n",
    "#             device=self.device,\n",
    "#             patience=patience,\n",
    "#             augment=True,\n",
    "#             hsv_h=0.1,\n",
    "#             hsv_s=0.7,\n",
    "#             hsv_v=0.4,\n",
    "#             translate=0.2,\n",
    "#             scale=0.3,\n",
    "#             fliplr=0.5,\n",
    "#             mosaic=1.0,\n",
    "#             mixup=0.2,\n",
    "#             pre_transform=self._apply_coral_augmentations,\n",
    "#             optimizer='AdamW',\n",
    "#             lr0=0.0005,\n",
    "#             lrf=0.005,\n",
    "#             warmup_epochs=8,\n",
    "#             weight_decay=0.05,\n",
    "#             label_smoothing=0.1,\n",
    "#             dropout=0.1\n",
    "#         )\n",
    "#         return self.model\n",
    "\n",
    "#     def evaluate(self, test_path):\n",
    "#         \"\"\"\n",
    "#         Generate detailed coral health report\n",
    "        \n",
    "#         Args:\n",
    "#             test_path (str): Path to test images\n",
    "            \n",
    "#         Returns:\n",
    "#             dict: Comprehensive evaluation metrics\n",
    "#         \"\"\"\n",
    "#         results = self.model.predict(\n",
    "#             source=test_path,\n",
    "#             conf=0.25,\n",
    "#             augment=False,\n",
    "#             device=self.device\n",
    "#         )\n",
    "        \n",
    "#         # Initialize metrics collection\n",
    "#         metrics = {\n",
    "#             'total_images': 0,\n",
    "#             'coral_count': 0,\n",
    "#             'health_distribution': {'Bleached':0, 'Dead':0, 'Healthy':0},\n",
    "#             'coverage': [],\n",
    "#             'per_image': []\n",
    "#         }\n",
    "        \n",
    "#         for result in results:\n",
    "#             img_metrics = self._process_image_result(result)\n",
    "#             metrics['total_images'] += 1\n",
    "#             metrics['coral_count'] += img_metrics['coral_count']\n",
    "#             for cls in self.class_names:\n",
    "#                 metrics['health_distribution'][cls] += img_metrics['health_distribution'][cls]\n",
    "#             metrics['coverage'].append(img_metrics['coverage'])\n",
    "#             metrics['per_image'].append(img_metrics)\n",
    "            \n",
    "#         self._generate_visual_report(metrics)\n",
    "#         return metrics\n",
    "\n",
    "#     def _process_image_result(self, result):\n",
    "#         \"\"\"Extract metrics from single image result\"\"\"\n",
    "#         img_metrics = {\n",
    "#             'filename': Path(result.path).name,\n",
    "#             'coral_count': 0,\n",
    "#             'health_distribution': {'Bleached':0, 'Dead':0, 'Healthy':0},\n",
    "#             'coverage': 0.0,\n",
    "#             'bboxes': []\n",
    "#         }\n",
    "        \n",
    "#         if result.boxes and result.masks:\n",
    "#             img_area = result.orig_shape[0] * result.orig_shape[1]\n",
    "#             coral_area = 0\n",
    "            \n",
    "#             for cls, conf, box, mask in zip(result.boxes.cls, result.boxes.conf, \n",
    "#                                           result.boxes.xyxy, result.masks):\n",
    "#                 cls_name = self.class_names[int(cls)]\n",
    "#                 img_metrics['health_distribution'][cls_name] += 1\n",
    "#                 img_metrics['coral_count'] += 1\n",
    "#                 coral_area += mask.area()\n",
    "#                 img_metrics['bboxes'].append({\n",
    "#                     'class': cls_name,\n",
    "#                     'confidence': conf.item(),\n",
    "#                     'bbox': box.tolist(),\n",
    "#                     'area': mask.area().item()\n",
    "#                 })\n",
    "            \n",
    "#             img_metrics['coverage'] = coral_area / img_area\n",
    "            \n",
    "#         return img_metrics\n",
    "\n",
    "#     def _generate_visual_report(self, metrics):\n",
    "#         \"\"\"Create visualizations for report\"\"\"\n",
    "#         plt.figure(figsize=(15, 5))\n",
    "        \n",
    "#         # Health distribution pie chart\n",
    "#         plt.subplot(1, 3, 1)\n",
    "#         plt.pie(metrics['health_distribution'].values(), \n",
    "#                 labels=metrics['health_distribution'].keys(),\n",
    "#                 autopct='%1.1f%%')\n",
    "#         plt.title('Coral Health Distribution')\n",
    "        \n",
    "#         # Coverage histogram\n",
    "#         plt.subplot(1, 3, 2)\n",
    "#         plt.hist(metrics['coverage'], bins=20)\n",
    "#         plt.title('Coral Coverage Distribution')\n",
    "#         plt.xlabel('Coverage Percentage')\n",
    "#         plt.ylabel('Image Count')\n",
    "        \n",
    "#         # Confidence distribution\n",
    "#         plt.subplot(1, 3, 3)\n",
    "#         confidences = [b['confidence'] for img in metrics['per_image'] for b in img['bboxes']]\n",
    "#         plt.hist(confidences, bins=20, color='green', alpha=0.7)\n",
    "#         plt.title('Detection Confidence Distribution')\n",
    "#         plt.xlabel('Confidence Score')\n",
    "        \n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig('coral_health_report.png', dpi=300)\n",
    "#         plt.close()\n",
    "        \n",
    "#         # Save detailed CSV report\n",
    "#         df = pd.DataFrame(metrics['per_image'])\n",
    "#         df.to_csv('detailed_coral_analysis.csv', index=False)\n",
    "\n",
    "# v7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dfd08354-79a6-41c6-93ea-393054dbdfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v7.2\n",
    "\n",
    "class CoralReefAnalyzer:\n",
    "    def __init__(self, pretrained='yolov8n-seg.pt'):\n",
    "        torch.cuda.empty_cache()\n",
    "        self.device = self._configure_device()\n",
    "        \n",
    "        # Try loading last.pt first, fallback to pretrained\n",
    "        try:\n",
    "            self.model = YOLO(\"runs/segment/train5/weights/last.pt\").to(self.device)\n",
    "            print(\"Resuming training from last.pt\")\n",
    "        except:\n",
    "            self.model = YOLO(pretrained).to(self.device)\n",
    "            print(\"Starting new training\")\n",
    "        \n",
    "        self.class_names = ['Bleached', 'Dead', 'Healthy']\n",
    "        \n",
    "\n",
    "    def _configure_device(self):\n",
    "        \"\"\"Safe device configuration\"\"\"\n",
    "        try:\n",
    "            if torch.cuda.is_available():\n",
    "                torch.backends.cudnn.benchmark = True\n",
    "                return 'cuda'\n",
    "            return 'cpu'\n",
    "        except RuntimeError as e:\n",
    "            print(f\"CUDA Error: {e} - Using CPU\")\n",
    "            return 'cpu'\n",
    "\n",
    "    def train(self, data, epochs=220, batch_size=8, imgsz=512, resume=False):\n",
    "        \"\"\"Efficient training with coral-optimized params\"\"\"\n",
    "        results = self.model.train(\n",
    "            data=data,\n",
    "            epochs=epochs,\n",
    "            batch=batch_size,\n",
    "            imgsz=imgsz,\n",
    "            device=self.device,\n",
    "            #augment=True,\n",
    "            hsv_h=0.05,  # Hue variation\n",
    "            hsv_s=0.5,   # Saturation\n",
    "            hsv_v=0.4,   # Value\n",
    "            fliplr=0.5,\n",
    "            optimizer='AdamW',\n",
    "            lr0=1e-4,\n",
    "            lrf=1e-3,\n",
    "            amp=True,  # Mixed precision\n",
    "            overlap_mask=True,\n",
    "            # mask_ratio=4,\n",
    "            weight_decay=0.05,\n",
    "            warmup_epochs=8,\n",
    "            patience=50,\n",
    "            resume=resume,\n",
    "            pretrained=\"runs/segment/train3/weights/best.pt\",\n",
    "            augment=False,\n",
    "            mask_ratio=2,\n",
    "            single_cls=False\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def analyze_reef(self, test_dir, conf=0.3):\n",
    "        \"\"\"Instance-level analysis with proper metrics\"\"\"\n",
    "        results = self.model.predict(\n",
    "            source=str(Path(test_dir)),\n",
    "            conf=conf,\n",
    "            device=self.device,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Initialize metrics\n",
    "        metrics = {\n",
    "            'true_labels': [],\n",
    "            'pred_labels': [],\n",
    "            'health': defaultdict(int),\n",
    "            'coverage': [],\n",
    "            'skipped_images': 0 , # ðŸš¨ Track mismatched pairs\n",
    "            'confusion': np.zeros((len(self.class_names), len(self.class_names))),  # ADD THIS\n",
    "            'total': len(results)  # ADD THIS TOO\n",
    "        }\n",
    "\n",
    "        for result in results:\n",
    "            # Get instance predictions\n",
    "            pred_classes = result.boxes.cls.cpu().numpy().astype(int)\n",
    "            true_classes = self._get_instance_true_labels(result.path)\n",
    "        \n",
    "            # ðŸš¨ Validate instance alignment\n",
    "            if len(pred_classes) != len(true_classes):\n",
    "                print(f\"Skipping {Path(result.path).name}: {len(pred_classes)} pred vs {len(true_classes)} true\")\n",
    "                metrics['skipped_images'] += 1\n",
    "                continue\n",
    "\n",
    "            # Update confusion matrix HERE\n",
    "            for t, p in zip(true_classes, pred_classes):\n",
    "                metrics['confusion'][t, p] += 1  # ACTUAL CONFUSION MATRIX UPDATE\n",
    "        \n",
    "            # Update metrics\n",
    "            metrics['true_labels'].extend(true_classes)\n",
    "            metrics['pred_labels'].extend(pred_classes)\n",
    "        \n",
    "            # Count health distribution\n",
    "            for cls_idx in pred_classes:\n",
    "                metrics['health'][self.class_names[cls_idx]] += 1\n",
    "\n",
    "            # ðŸš¨ FIXED INDENTATION: Calculate coverage PER IMAGE\n",
    "            if result.masks:\n",
    "                total_area = result.orig_shape[0] * result.orig_shape[1]\n",
    "                coral_area = sum(m.data.sum().item() for m in result.masks)\n",
    "                metrics['coverage'].append(coral_area / total_area)\n",
    "\n",
    "        # ðŸš¨ SAFE METRIC CALCULATION\n",
    "        try:\n",
    "            if len(metrics['true_labels']) == 0:\n",
    "                raise ValueError(\"No valid instances for metric calculation\")\n",
    "            \n",
    "            metrics.update({\n",
    "                'precision': precision_score(metrics['true_labels'], metrics['pred_labels'], \n",
    "                               average='weighted', zero_division=0),\n",
    "                'recall': recall_score(metrics['true_labels'], metrics['pred_labels'],\n",
    "                                 average='weighted', zero_division=0),\n",
    "                'f1': f1_score(metrics['true_labels'], metrics['pred_labels'],\n",
    "                             average='weighted', zero_division=0),\n",
    "                'accuracy': accuracy_score(metrics['true_labels'], metrics['pred_labels'])\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Metric calculation failed: {str(e)}\")\n",
    "            metrics.update({'precision': 0, 'recall': 0, 'f1': 0, 'accuracy': 0})\n",
    "\n",
    "        # Generate reports\n",
    "        self._visual_report(metrics)\n",
    "        self._print_summary(metrics)\n",
    "    \n",
    "        return metrics\n",
    "\n",
    "    def _process_result(self, result):\n",
    "        \"\"\"Process detection results safely\"\"\"\n",
    "        metrics = {\n",
    "            'health': {cls:0 for cls in self.class_names},\n",
    "            'coverage': None,\n",
    "            'pred': None\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            if result.boxes and result.masks:\n",
    "                total_area = result.orig_shape[0] * result.orig_shape[1]\n",
    "                coral_area = 0\n",
    "                counts = [0]*3\n",
    "                \n",
    "                for cls, mask in zip(result.boxes.cls.cpu().numpy(), result.masks):\n",
    "                    cls_idx = int(cls)\n",
    "                    counts[cls_idx] += 1\n",
    "                    coral_area += mask.data.sum().item()\n",
    "                \n",
    "                metrics['coverage'] = coral_area / total_area if total_area > 0 else 0\n",
    "                metrics['pred'] = np.argmax(counts)\n",
    "                    \n",
    "                for i, cls in enumerate(self.class_names):\n",
    "                    metrics['health'][cls] = counts[i]\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Processing error: {e}\")\n",
    "            \n",
    "        return metrics\n",
    "\n",
    "    def _get_instance_true_labels(self, img_path):\n",
    "        \"\"\"Match labels using base name before .rf. hash\"\"\"\n",
    "        img_path = Path(img_path)\n",
    "    \n",
    "        # Extract base name before first .rf.\n",
    "        base_part = img_path.name.split(\".rf.\")[0]\n",
    "        label_dir = img_path.parent.parent / \"labels\"\n",
    "    \n",
    "        # Find first matching label file\n",
    "        label_files = list(label_dir.glob(f\"{base_part}.rf.*.txt\"))\n",
    "    \n",
    "        if not label_files:\n",
    "            return []\n",
    "    \n",
    "        # Always use first match if multiple exist\n",
    "        label_path = label_files[0]\n",
    "    \n",
    "        true_labels = []\n",
    "        try:\n",
    "            with open(label_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 5:  # class_id + bbox + polygon\n",
    "                        true_labels.append(int(parts[0]))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {label_path.name}: {str(e)}\")\n",
    "    \n",
    "        return true_labels\n",
    "\n",
    "    def _visual_report(self, metrics):\n",
    "        \"\"\"Generate visual analysis report\"\"\"\n",
    "        plt.figure(figsize=(18,6))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        plt.subplot(1,2,1)\n",
    "        sns.heatmap(\n",
    "            metrics['confusion'], \n",
    "            annot=True, \n",
    "            fmt='.0f',\n",
    "            xticklabels=self.class_names,\n",
    "            yticklabels=self.class_names,\n",
    "            cmap='Blues',\n",
    "            annot_kws={\"size\": 14, \"weight\": \"bold\"},  # Larger, clearer numbers\n",
    "            cbar=False\n",
    "        )\n",
    "        plt.title('Coral Health Confusion Matrix\\n', fontsize=14, pad=20)\n",
    "        plt.xlabel('Predicted Class', fontsize=12)\n",
    "        plt.ylabel('True Class', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "    \n",
    "        # Health Distribution\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.bar(\n",
    "            self.class_names,\n",
    "            [metrics['health'][cls] for cls in self.class_names],\n",
    "            color=['lightcoral', 'gray', 'mediumaquamarine'],\n",
    "            edgecolor='black'\n",
    "        )\n",
    "        plt.title('Coral Health Distribution\\n', fontsize=14)\n",
    "        plt.ylabel('Count', fontsize=12)\n",
    "        plt.xticks(fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('coral_health_report.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    def _print_summary(self, metrics):\n",
    "        \"\"\"Print enhanced console summary with metrics\"\"\"\n",
    "        total_corals = sum(metrics['health'].values())\n",
    "    \n",
    "        print(\"\\n=== Coral Reef Analysis Report ===\")\n",
    "        print(f\"Images Analyzed: {metrics['total']}\")\n",
    "        print(f\"Total Coral Colonies Detected: {total_corals}\")\n",
    "    \n",
    "        print(\"\\nClassification Metrics:\")\n",
    "        print(f\"- Precision (Weighted): {metrics['precision']:.2%}\")\n",
    "        print(f\"- Recall (Weighted):    {metrics['recall']:.2%}\")\n",
    "        print(f\"- F1-Score (Weighted):  {metrics['f1']:.2%}\")\n",
    "        print(f\"- Accuracy:             {metrics['accuracy']:.2%}\")\n",
    "    \n",
    "        print(\"\\nHealth Distribution:\")\n",
    "        for cls in self.class_names:\n",
    "            count = metrics['health'][cls]\n",
    "            print(f\"- {cls}: {count} ({count/total_corals:.1%})\" if total_corals > 0 else f\"- {cls}: 0\")\n",
    "    \n",
    "        print(f\"\\nAverage Coral Coverage: {np.mean(metrics['coverage']):.1%}\")\n",
    "        print(f\"Detection Confidence Threshold: {self.model.predictor.args.conf}\")\n",
    "        \n",
    "    def show_masks(self, image_path):\n",
    "        results = self.model.predict(image_path)\n",
    "        for result in results:\n",
    "            masks = result.masks\n",
    "            img = result.plot()  # Automatically plots masks\n",
    "            cv2.imshow(\"Segmentation\", img)\n",
    "            cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af8ab227-9a8f-4928-b8c1-3feea197c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     analyzer = CoralReefAnalyzer(\n",
    "#         pretrained='yolov8n-seg.pt'\n",
    "#     )\n",
    "\n",
    "#     print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.2f}GB\")\n",
    "\n",
    "#     # Your dataset root (no need to modify YAML)\n",
    "#     data_root = r\"C:\\Users\\Rugved\\Downloads\\marjan-segmentaion.v15i.yolov8\"\n",
    "    \n",
    "#     # Path to your existing YAML (keep it unchanged)\n",
    "#     yaml_path = r\"C:\\Users\\Rugved\\Downloads\\marjan-segmentaion.v15i.yolov8\\data.yaml\"\n",
    "    \n",
    "#     print(\"Training coral health model...\")\n",
    "#     # analyzer.train(epochs=220)\n",
    "\n",
    "#     try:\n",
    "#         analyzer.train(\n",
    "#             data=yaml_path,\n",
    "#             epochs=135,\n",
    "#             batch_size=16,\n",
    "#             imgsz=512,\n",
    "#             resume=True\n",
    "#         )\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error: {e}\\nRetrying with safer settings...\")\n",
    "#         analyzer.train(\n",
    "#             data=yaml_path,\n",
    "#             epochs=50,\n",
    "#             batch_size=4,\n",
    "#             imgsz=480,\n",
    "#             resume=True\n",
    "#         )\n",
    "    \n",
    "#     # print(\"\\nAnalyzing reef health...\")\n",
    "#     # metrics = analyzer.analyze_reef(test_dir=Path(data_root)/\"test/images\")\n",
    "\n",
    "#     # #analyzer.show_masks(\"test_image.jpg\")  # Visual verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d6642b86-7cb6-4de3-93fc-ea0e274cfcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from last.pt\n"
     ]
    }
   ],
   "source": [
    "#Cell 3\n",
    "# Initialize analyzer with trained weights\n",
    "analyzer = CoralReefAnalyzer(\n",
    "    pretrained='runs/segment/train5/weights/best.pt'  # Path to your trained weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "abf7f248-d962-430e-98fe-60def5010f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Dataset Paths (Modify accordingly)\n",
    "data_root = Path(r\"C:\\Users\\Rugved\\Downloads\\marjan-segmentaion.v15i.yolov8\")\n",
    "yaml_path = data_root/\"data.yaml\"\n",
    "test_dir = data_root/\"test/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "95e329cc-2fd9-4857-9444-c4bd47faac3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing reef health...\n",
      "Skipping 02exuae18r-JPG-800x0_q85_jpg.rf.3e57a2f14e62dc6fcfec54e4b76b2353.jpg: 4 pred vs 3 true\n",
      "Skipping 107_png_jpg.rf.295156cf15525ec323b8938d8e3ca6ba.jpg: 3 pred vs 5 true\n",
      "Skipping 11023816893_9994f554e2_o_jpg.rf.1b0dce9382768baf7ac09c732b4de67b.jpg: 2 pred vs 3 true\n",
      "Skipping 11333883796_e74aa9bd17_o_jpg.rf.06960501ef46e5e1d2721c2539a466a0.jpg: 4 pred vs 11 true\n",
      "Skipping 115_jpg.rf.19e02b603036b792848ddb2d1bed38a5.jpg: 4 pred vs 3 true\n",
      "Skipping 122_png_jpg.rf.3d69c13cb48c7c73e355ac14cd6d1533.jpg: 0 pred vs 2 true\n",
      "Skipping 129_png_jpg.rf.177802fe0877de3c99d4fe96cfecc2b3.jpg: 0 pred vs 1 true\n",
      "Skipping 129_png_jpg.rf.18222340ce6ef46f8f459c441366ef7f.jpg: 0 pred vs 1 true\n",
      "Skipping 129_png_jpg.rf.385dfba37326d5da0ac857a258bc1d36.jpg: 4 pred vs 1 true\n",
      "Skipping 129_png_jpg.rf.e9dab777a541ab0b9c80de832e03e3bc.jpg: 2 pred vs 1 true\n",
      "Skipping 12_png_jpg.rf.6ef7b5a3ead51a94f8c4e2d924d5725a.jpg: 0 pred vs 1 true\n",
      "Skipping 131_png_jpg.rf.c1a9158627b12633a2064fb514231ddc.jpg: 1 pred vs 2 true\n",
      "Skipping 135_png_jpg.rf.3f78cf3df9be1c75df78c4db9801dfd2.jpg: 2 pred vs 4 true\n",
      "Skipping 15274978947_0b3901fffc_o_jpg.rf.e7a804e53f6e8cb6ca9c9791bf8f6f7d.jpg: 0 pred vs 2 true\n",
      "Skipping 15598304567_45c1721b6c_o_jpg.rf.56ad86a772dfd95603326106e1368d55.jpg: 2 pred vs 3 true\n",
      "Skipping 16051547956_12d5b6c365_o_jpg.rf.bfd5729df479b4c01c15d9e5bfd28c79.jpg: 2 pred vs 1 true\n",
      "Skipping 16821031211_c5c5d9b4f8_o_jpg.rf.03ebee67cac46f917e82056b645be6d6.jpg: 0 pred vs 2 true\n",
      "Skipping 16821031211_c5c5d9b4f8_o_jpg.rf.f643caf78cf5f1b990106ae67a6ac6db.jpg: 0 pred vs 2 true\n",
      "Skipping 1ohfxw12mr-JPG-800x0_q85_jpg.rf.d565f8ade5502a640a5c11e07026b1d3.jpg: 4 pred vs 5 true\n",
      "Skipping 20_png_jpg.rf.3f98a890dc5a78f5ff8ee16851586716.jpg: 2 pred vs 6 true\n",
      "Skipping 20_png_jpg.rf.fb07e6477774c93fa4f2791985cd8618.jpg: 2 pred vs 6 true\n",
      "Skipping 21371610446_a98232091b_o_jpg.rf.5ede8d5905fe17147f1f3fec50e2bd31.jpg: 1 pred vs 2 true\n",
      "Skipping 21470830162_8e33d13683_b_jpg.rf.20f3ab99e67466fcfe4256ef5d68f89b.jpg: 0 pred vs 1 true\n",
      "Skipping 22_png_jpg.rf.8d8ea2cdca7d30156df4be5b4e28df0f.jpg: 2 pred vs 3 true\n",
      "Skipping 244_jpg.rf.94a95978c7c439798eb947ab90a05e09.jpg: 5 pred vs 7 true\n",
      "Skipping 246_png_jpg.rf.ba2deec51e33183e5bf0051435eecfb8.jpg: 1 pred vs 3 true\n",
      "Skipping 252_jpg.rf.cdf8b0a272cfa76216c664ecf4a8a7ab.jpg: 0 pred vs 2 true\n",
      "Skipping 263_jpg.rf.87761ed730c17754d94934b676e038e0.jpg: 4 pred vs 5 true\n",
      "Skipping 281_jpg.rf.b39042519ae10bde1488bda6691ed492.jpg: 0 pred vs 2 true\n",
      "Skipping 305_png_jpg.rf.e23819e401162e8333f8cad8329eefca.jpg: 0 pred vs 1 true\n",
      "Skipping 314_jpg.rf.7774199ea99847d89d0a0cb1eb97e89b.jpg: 7 pred vs 8 true\n",
      "Skipping 315_png_jpg.rf.9dcf6d44e4abced99b09e91542fea3a8.jpg: 2 pred vs 1 true\n",
      "Skipping 397_jpg.rf.cc610dcea98bc04528d6887df6896339.jpg: 2 pred vs 3 true\n",
      "Skipping 399_jpg.rf.13dd628009269a4c9cb659900efa5947.jpg: 0 pred vs 1 true\n",
      "Skipping 3evxxhmt4t-JPG-800x0_q85_jpg.rf.d51d697afcc88293652e9be6b925d69b.jpg: 1 pred vs 8 true\n",
      "Skipping 3wawfdmptt-JPG-800x0_q85_jpg.rf.1298a608e301956decdbfbc51427e376.jpg: 2 pred vs 3 true\n",
      "Skipping 407_jpg.rf.6d0082969f0bed355d83e54f774cf8fd.jpg: 0 pred vs 1 true\n",
      "Skipping 40_png_jpg.rf.669332fea3900ecfaf8ae83c1574f4a8.jpg: 2 pred vs 3 true\n",
      "Skipping 414_jpg.rf.9604f400f5acf03e6d002848307a78d6.jpg: 4 pred vs 6 true\n",
      "Skipping 425_jpg.rf.5aab984c8ee0719101561c506cb8c6ae.jpg: 0 pred vs 1 true\n",
      "Skipping 426_jpg.rf.a6a1bc6bd286d07db43bfc7a44e67294.jpg: 0 pred vs 2 true\n",
      "Skipping 43_jpg.rf.c97f788841b0cc79646169c759c17a9e.jpg: 2 pred vs 3 true\n",
      "Skipping 43_png_jpg.rf.04a06541acbd89c105fbb125e69b0d09.jpg: 1 pred vs 2 true\n",
      "Skipping 43_png_jpg.rf.60c7bf6cb96658e5ff2a05fc65d88b20.jpg: 1 pred vs 2 true\n",
      "Skipping 4424086363_af89dc30ea_o_jpg.rf.0bc1e2ee6aaf8f92777543f669d43f8d.jpg: 2 pred vs 1 true\n",
      "Skipping 4424086363_af89dc30ea_o_jpg.rf.eb13bcf350102a54baa5f10de467ecab.jpg: 0 pred vs 1 true\n",
      "Skipping 442_jpg.rf.1f8ec56f001977628c75ac1c53af389a.jpg: 2 pred vs 5 true\n",
      "Skipping 443_jpg.rf.07c1797ffa3c48948f65c1759c4a28d3.jpg: 0 pred vs 2 true\n",
      "Skipping 443_jpg.rf.dabd4bd1d199585fc21e65cdeb0c01d0.jpg: 1 pred vs 2 true\n",
      "Skipping 447_png_jpg.rf.f89e0ff362102205f5262bfae8ac62fa.jpg: 1 pred vs 2 true\n",
      "Skipping 45_jpg.rf.ac769854c93312964e7a7bd97a77f615.jpg: 3 pred vs 2 true\n",
      "Skipping 460_jpg.rf.ae3a32b2b63cc5108e6903553d03580c.jpg: 2 pred vs 4 true\n",
      "Skipping 4665214905_3ba94454eb_b_jpg.rf.08364954a236b0681e79b29d92f1c6bd.jpg: 2 pred vs 3 true\n",
      "Skipping 466_jpg.rf.0877a73483e800528f8cfe2f2e6a2ad6.jpg: 1 pred vs 5 true\n",
      "Skipping 466_jpg.rf.1c5e7a6a7ba82203be05a0aaa6ce41a7.jpg: 1 pred vs 5 true\n",
      "Skipping 466_jpg.rf.36ffb8ac38273ee06e29a9308f0ac7a6.jpg: 3 pred vs 5 true\n",
      "Skipping 4695377101_03d3573df4_o_jpg.rf.14cf44c36ba271c00ec34c0ff065c693.jpg: 0 pred vs 1 true\n",
      "Skipping 475_jpg.rf.ef74921616a6f47779cc221bdb06816e.jpg: 0 pred vs 2 true\n",
      "Skipping 488_jpg.rf.1fb21c27e8fc075bfc4587c473601239.jpg: 1 pred vs 2 true\n",
      "Skipping 488_jpg.rf.8ac77b8fd7bf3be3661349bb6306f91e.jpg: 1 pred vs 2 true\n",
      "Skipping 488_jpg.rf.8df9710f2c48674ebb5cd3dfcffafd3d.jpg: 1 pred vs 2 true\n",
      "Skipping 490_jpg.rf.9eb10f5369a7a05142588da39117276f.jpg: 2 pred vs 1 true\n",
      "Skipping 494_jpg.rf.fac918d84e94cb94f3fcaa6c7cb02f2b.jpg: 5 pred vs 6 true\n",
      "Skipping 4957295366_001c80efc5_o_jpg.rf.a1905c8ba7f9fca633eb7a4286b02df1.jpg: 2 pred vs 3 true\n",
      "Skipping 496_jpg.rf.4580cb7f8356c70b6cfec8c6ca3bd748.jpg: 1 pred vs 2 true\n",
      "Skipping 496_jpg.rf.62c8d7119ff4acf2b43e06dc5e3faf7d.jpg: 1 pred vs 2 true\n",
      "Skipping 4995358229_ccf310e19c_o_jpg.rf.b695b6a2d6b3c9c1388cdfb4e3dd4f7b.jpg: 2 pred vs 1 true\n",
      "Skipping 4alhei5zwo-JPG-800x0_q85_jpg.rf.8e9415427b2dc91e94b6ca32c7d85fa9.jpg: 1 pred vs 2 true\n",
      "Skipping 4og38z56a8-JPG-800x0_q85_jpg.rf.9bfdad2e5e587d337f2ad6bc41b43263.jpg: 1 pred vs 2 true\n",
      "Skipping 4og38z56a8-JPG-800x0_q85_jpg.rf.9f85a5de8a55d2a782bd2515a1099818.jpg: 0 pred vs 2 true\n",
      "Skipping 503_jpg.rf.d33315d656ce6e56424e0733cbda92cc.jpg: 2 pred vs 3 true\n",
      "Skipping 514_png_jpg.rf.be3960512836d201806a55ad5077a27e.jpg: 4 pred vs 1 true\n",
      "Skipping 5160419996_ff4ba8452c_o_jpg.rf.9645c25f19cea15952403fb14a7556bb.jpg: 2 pred vs 1 true\n",
      "Skipping 517_png_jpg.rf.1786cca5732d81878dd21bc6846b3761.jpg: 0 pred vs 4 true\n",
      "Skipping 5199635092_e2354a3dc0_o_jpg.rf.1e95d9bcc4c0ccf0e812b549e71fe273.jpg: 0 pred vs 2 true\n",
      "Skipping 5199635092_e2354a3dc0_o_jpg.rf.c8f659fc43ff3318e892af3f89b339be.jpg: 1 pred vs 2 true\n",
      "Skipping 5199635092_e2354a3dc0_o_jpg.rf.d0a5fa783d89d8ee4ff427adc77a37ba.jpg: 1 pred vs 2 true\n",
      "Skipping 51_png_jpg.rf.45532881ba4d2254fb0a3e3e01c1ee21.jpg: 2 pred vs 4 true\n",
      "Skipping 522_png_jpg.rf.2a1c547f1594b7a640cee25d7437e2ae.jpg: 0 pred vs 2 true\n",
      "Skipping 522_png_jpg.rf.48e4c6a5a32fa959d4548100e9faf06e.jpg: 1 pred vs 2 true\n",
      "Skipping 53_jpg.rf.bb95eafcee1b6ef4d1d809e562d918e1.jpg: 3 pred vs 1 true\n",
      "Skipping 53_jpg.rf.bc191bc19854004e6cc7ea48e290b46e.jpg: 3 pred vs 1 true\n",
      "Skipping 53_jpg.rf.e902640429492322330613e803929caf.jpg: 3 pred vs 1 true\n",
      "Skipping 540_jpg.rf.064add3a4d97c6cdcea0af5dcb2c4e17.jpg: 1 pred vs 2 true\n",
      "Skipping 550_jpg.rf.48f2d2a42148be28ca45a92398ee6680.jpg: 0 pred vs 1 true\n",
      "Skipping 575_jpg.rf.2e88e12684806294db60344e769d112b.jpg: 1 pred vs 2 true\n",
      "Skipping 586_jpg.rf.7e11b7311c046edadffc51c38becaaa8.jpg: 1 pred vs 2 true\n",
      "Skipping 586_jpg.rf.eaeedee5082694779a96b40ef6d54b3f.jpg: 1 pred vs 2 true\n",
      "Skipping 5_png_jpg.rf.88b5b4a4c297743f97077ddf4cb9ca5f.jpg: 0 pred vs 3 true\n",
      "Skipping 5vfibr2hki-JPG-pointpk179771208-thumbnail_jpg.rf.129ee4cc2903ff24b555c546e0ac0c64.jpg: 0 pred vs 1 true\n",
      "Skipping 608_png_jpg.rf.0cd6c0d5bb9a8cd54fcc8371cb7b73be.jpg: 1 pred vs 6 true\n",
      "Skipping 6207765253_f0c6cc5162_b_jpg.rf.e816457931fcf0e14cfba83b3d180325.jpg: 1 pred vs 14 true\n",
      "Skipping 62_png_jpg.rf.65dfeea16fc64f835cf53c0c0f6a53d2.jpg: 2 pred vs 3 true\n",
      "Skipping 6392318609_c65a9aed4d_o_jpg.rf.e2e21c0e84970d12a9614609318dc4c3.jpg: 2 pred vs 5 true\n",
      "Skipping 63_png_jpg.rf.02b2d6a9ce1bed298748812e771c6d4d.jpg: 0 pred vs 2 true\n",
      "Skipping 648_png_jpg.rf.393aaaef8b7034cd995f4a807734b885.jpg: 1 pred vs 4 true\n",
      "Skipping 65_png_jpg.rf.540d5cb9ecd3869e1b9c15fcce5fad8d.jpg: 2 pred vs 3 true\n",
      "Skipping 68_png_jpg.rf.26c034adef91a93da269eb26593cbb74.jpg: 2 pred vs 3 true\n",
      "Skipping 6an9vdgjwl-JPG-800x0_q85_jpg.rf.9256638e474f622ca02e5a1e275a9861.jpg: 3 pred vs 1 true\n",
      "Skipping 6an9vdgjwl-JPG-800x0_q85_jpg.rf.a4c0b371e3579acc47eea0243e1387b5.jpg: 2 pred vs 1 true\n",
      "Skipping 6js9n790zp-JPG-800x0_q85_jpg.rf.27ff294eb0a0f835ecb8630df5e91f83.jpg: 2 pred vs 3 true\n",
      "Skipping 709_png_jpg.rf.d1d625ae1ef7d4c34a527d0a3888a0a8.jpg: 2 pred vs 6 true\n",
      "Skipping 7660585356_8b49a5acc2_o_jpg.rf.a79f513d33f151084a5dfe5fdd576f6f.jpg: 9 pred vs 10 true\n",
      "Skipping 7660585356_8b49a5acc2_o_jpg.rf.c3584e6930da4fcb4a3ce4ff671f19aa.jpg: 4 pred vs 10 true\n",
      "Skipping 7b4a60itds-JPG-800x0_q85_jpg.rf.d7089c7829de63842a2c26c905638c48.jpg: 1 pred vs 2 true\n",
      "Skipping 80xoovohi6-JPG-800x0_q85_jpg.rf.a58b3a027e89af94f0832e3e732ef30a.jpg: 5 pred vs 7 true\n",
      "Skipping 82_png_jpg.rf.370b948c2ca6238aa95a8e297f7fdba0.jpg: 1 pred vs 2 true\n",
      "Skipping 85_png_jpg.rf.cc2f57c3cd10f1f8a477423f710aeab0.jpg: 2 pred vs 4 true\n",
      "Skipping 8677946826_be2f953cb0_o_jpg.rf.0c2652da9a9124c34d60163b8158b2b5.jpg: 1 pred vs 5 true\n",
      "Skipping 881_jpg.rf.23f0d74034f6ae81dcfe57d450191dcc.jpg: 0 pred vs 1 true\n",
      "Skipping 8_png_jpg.rf.9c4f5894dc260778f0e8b9876910f6a9.jpg: 0 pred vs 1 true\n",
      "Skipping 8sgn50f1sj-JPG-800x0_q85_jpg.rf.7376bb7a69c7cbff8cc15d918b20fdf5.jpg: 2 pred vs 4 true\n",
      "Skipping 906_jpg.rf.8241d8d8edde11830041ed76e7891fbe.jpg: 0 pred vs 1 true\n",
      "Skipping 90_png_jpg.rf.409a3f21b0cf1eda50591da98191d940.jpg: 4 pred vs 5 true\n",
      "Skipping 9211069421_64421481ed_o_jpg.rf.0962907252291720b4d28d2a30c289d2.jpg: 1 pred vs 4 true\n",
      "Skipping 96_png_jpg.rf.5d79221c40c20c157a8960d82e86a884.jpg: 1 pred vs 2 true\n",
      "Skipping 97_png_jpg.rf.62ddd9127ac3d2233353dc3cb44af7ba.jpg: 2 pred vs 3 true\n",
      "Skipping 99ox1wo10u-JPG-pointpk113290398-thumbnail_jpg.rf.2bb20ef9b8cb967967595f921c91fe31.jpg: 0 pred vs 1 true\n",
      "Skipping 9jrtgcwlbc-JPG-pointpk179791095-thumbnail_jpg.rf.406cd4e1e61d763fa5b060b6a1293769.jpg: 0 pred vs 1 true\n",
      "Skipping 9pmckeu7ri-JPG-800x0_q85_jpg.rf.112974eb6c8a8936059361f9e0a5919c.jpg: 2 pred vs 5 true\n",
      "Skipping B103_png_jpg.rf.25778094d65e6f5ad6a798db431bd23d.jpg: 1 pred vs 10 true\n",
      "Skipping B105_png_jpg.rf.076da6417f35f99727212af7c119902b.jpg: 8 pred vs 9 true\n",
      "Skipping B108_png_jpg.rf.becca083dea0a2f073ec310f78b9350b.jpg: 9 pred vs 12 true\n",
      "Skipping B10_png_jpg.rf.7a0b4a9689df9a9b54a4d9e342100503.jpg: 5 pred vs 21 true\n",
      "Skipping B111_png_jpg.rf.9067ef6cf1453e5f41651a08c3b3e7e6.jpg: 4 pred vs 6 true\n",
      "Skipping B112_png_jpg.rf.97681101e1b7bde8ef4937722718e57c.jpg: 4 pred vs 12 true\n",
      "Skipping B121_png_jpg.rf.5ebdf4fc62cd80cbd064c849fdfbdc7a.jpg: 4 pred vs 13 true\n",
      "Skipping B131_png_jpg.rf.be0a8e6000445077f6f318425c9b2e62.jpg: 3 pred vs 7 true\n",
      "Skipping B29_png_jpg.rf.08e575561a402d3d7ba657d8e36ba96d.jpg: 5 pred vs 10 true\n",
      "Skipping B46_png_jpg.rf.db5414b596f7430b1005d6592343ca60.jpg: 2 pred vs 9 true\n",
      "Skipping B48_png_jpg.rf.f5ae475dc641a6b3b2b3677330438e93.jpg: 2 pred vs 3 true\n",
      "Skipping B52_png_jpg.rf.7d646fa2bafdb70b1a3e5e3106d72f6a.jpg: 1 pred vs 3 true\n",
      "Skipping B56_png_jpg.rf.463f768ecff9b14657f1c219ca136ec0.jpg: 1 pred vs 5 true\n",
      "Skipping H31_jpg.rf.7176c41d3182bc00edaa52a0d76eb5aa.jpg: 3 pred vs 4 true\n",
      "Skipping H34_jpg.rf.6d05c6a67b189822c6b030a3cc97c83c.jpg: 1 pred vs 2 true\n",
      "Skipping H49_jpg.rf.e3548d5671384688527b8c34ea6a670e.jpg: 2 pred vs 4 true\n",
      "Skipping H8_jpg.rf.5f59d79a16122735d98ca6e0c38057f1.jpg: 1 pred vs 2 true\n",
      "Skipping OceanImageBank_FabriceDudenhofer_10_jpg.rf.5268d62410571329985725f4c54b195f.jpg: 5 pred vs 10 true\n",
      "Skipping OceanImageBank_TheOceanAgency_Bleaching_18_jpg.rf.2c283d939a5f956a827fe7fc9c66179a.jpg: 10 pred vs 8 true\n",
      "Skipping OceanImageBank_TheOceanAgency_Bleaching_56_jpg.rf.b40f93237db56b4682247e360ae2bb39.jpg: 3 pred vs 6 true\n",
      "Skipping OceanImageBank_TheOceanAgency_Fluorescing_15_jpeg_jpg.rf.5232cc930ab7acca8a60df381437c2e3.jpg: 2 pred vs 3 true\n",
      "Skipping OceanImageBank_TheOceanAgency_Fluorescing_15_jpeg_jpg.rf.ef37bdd71fb8d18435a3f129188efc8b.jpg: 1 pred vs 3 true\n",
      "Skipping OceanImageBank_TheOceanAgency_Fluorescing_16_jpeg_jpg.rf.8e62918d87c084acaaa49cfbbad7f195.jpg: 4 pred vs 9 true\n",
      "Skipping OceanImageBank_TheOceanAgency_Fluorescing_17_jpeg_jpg.rf.d2ada20026ec330236a060ec12d870bd.jpg: 0 pred vs 14 true\n",
      "Skipping OceanImageBank_TheOceanAgency_Fluorescing_24_jpeg_jpg.rf.dcb84943c20d305205a412ebf60df384.jpg: 3 pred vs 5 true\n",
      "Skipping bleached1-Copy_jpg.rf.eb005aa0bdf0580a67269b805c57a4c0.jpg: 3 pred vs 6 true\n",
      "Skipping bleached2-Copy-2-_jpg.rf.ec24e6174d8a116645b47f5f05fbc492.jpg: 0 pred vs 5 true\n",
      "Skipping bleached2-Copy_jpg.rf.72b125e475b81ffb4f7ab82796d5ec8b.jpg: 1 pred vs 2 true\n",
      "Skipping c2etggpk7i-JPG-800x0_q85_jpg.rf.af6eaba4dd52c350ef85a18210c9f3ec.jpg: 1 pred vs 2 true\n",
      "Skipping dtsjvhs9hd-JPG-800x0_q85_jpg.rf.7a9e8bf54399bc3709167921ca45f795.jpg: 4 pred vs 3 true\n",
      "Skipping free-living-21_jpg.rf.57aeb9ab3b0de425d0a379381a21796b.jpg: 1 pred vs 3 true\n",
      "Skipping fy7p8hocd7-JPG-800x0_q85_jpg.rf.6172be78736a2d4df28d9709939fd56d.jpg: 1 pred vs 2 true\n",
      "Skipping h14_jpg.rf.7bfcba00996f53f372f5d1820fb3c887.jpg: 7 pred vs 8 true\n",
      "Skipping h26_jpg.rf.4f61cfa567324ae8db84696745db106a.jpg: 4 pred vs 13 true\n",
      "Skipping h29_jpg.rf.1135009cfaedf047954e5b995fd2920e.jpg: 2 pred vs 3 true\n",
      "Skipping h32_jpg.rf.9f4fe50987a3640b3309f41e916a0b13.jpg: 1 pred vs 2 true\n",
      "Skipping h36_jpg.rf.acfc70c466214b29e40e32aaff718aff.jpg: 3 pred vs 5 true\n",
      "Skipping h45_jpg.rf.57446b8123067647d60ac86f76d5535b.jpg: 2 pred vs 4 true\n",
      "Skipping h47_jpg.rf.17dd13e16c0e36a89885d894ecf66369.jpg: 1 pred vs 12 true\n",
      "Skipping h53_jpg.rf.811a55803de9d62059da5e123703e2b9.jpg: 0 pred vs 5 true\n",
      "Skipping pjs91j5s1n-JPG-800x0_q85_jpg.rf.caca0c48331c122719648a9576c94a03.jpg: 1 pred vs 5 true\n",
      "Skipping swkljsbzmw-JPG-800x0_q85_jpg.rf.e857fdc38b367121beffc77139842e45.jpg: 5 pred vs 7 true\n",
      "Skipping swkljsbzmw-JPG-800x0_q85_jpg.rf.e95b357abc321363c4fc53655df41dc1.jpg: 5 pred vs 7 true\n",
      "\n",
      "=== Coral Reef Analysis Report ===\n",
      "Images Analyzed: 354\n",
      "Total Coral Colonies Detected: 311\n",
      "\n",
      "Classification Metrics:\n",
      "- Precision (Weighted): 96.14%\n",
      "- Recall (Weighted):    96.14%\n",
      "- F1-Score (Weighted):  96.14%\n",
      "- Accuracy:             96.14%\n",
      "\n",
      "Health Distribution:\n",
      "- Bleached: 81 (26.0%)\n",
      "- Dead: 152 (48.9%)\n",
      "- Healthy: 78 (25.1%)\n",
      "\n",
      "Average Coral Coverage: 22.4%\n",
      "Detection Confidence Threshold: 0.7\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Model Testing and Reporting\n",
    "print(\"\\nAnalyzing reef health...\")\n",
    "metrics = analyzer.analyze_reef(\n",
    "    test_dir=test_dir,\n",
    "    conf=0.48  # Adjust confidence threshold as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa72b7d-9366-4a77-9b57-db80b57c9754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Visual Verification (Optional)\n",
    "analyzer.show_masks(r\"C:\\Users\\Rugved\\Downloads\\marjan-segmentaion.v15i.yolov8\\test\\images\\OceanImageBank_FabriceDudenhofer_10_jpg.rf.5268d62410571329985725f4c54b195f.jpg\")  # Visual inspection of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "864a75c7-c52e-4a9d-821e-8cc3ca3acd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last saved epoch: 0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1fdddec-c411-4ad5-aaa7-fd40b6ab6929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # Should show 2.0.0+cu117 or similar\n",
    "print(torch.cuda.is_available())  # Should be True if using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f579ce8-2958-4c49-9945-80b548e6a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in a new cell\n",
    "analyzer.stop_training()  # If using the signal handler method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acbb6a4d-0944-46e0-b4c7-79a21061438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load last checkpoint\n",
    "ckpt_path = 'runs/segment/train5/weights/last.pt'\n",
    "ckpt = torch.load(ckpt_path)\n",
    "\n",
    "# Preserve progress but change epoch limit\n",
    "ckpt['train_args']['epochs'] = 135  # New total epochs\n",
    "ckpt['start_epoch'] = ckpt['epoch']  # Continue from last saved epoch\n",
    "torch.save(ckpt, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f23753-5cfe-4bc7-af12-088c9eba56da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
